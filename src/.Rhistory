log_kappa   = 0
)
?dcar_proper
M(diag(1, n, n) - rho*solve(M)%*%W)
M%*%(diag(1, n, n) - rho*solve(M)%*%W)
solve(M)
M
diag(M)
dim(diag(M))
diag(M)%*%(diag(1, n, n) - rho*solve(diag(M))%*%W)
matrix(C, n, n)
diag(M)%*%(diag(1, n, n) - rho*solve(diag(M))%*%matrix(C, n,n))
Q = diag(M)%*%(diag(1, n, n) - rho*solve(diag(M))%*%matrix(C, n,n))
solve(Q)
solve(diag(M))%*%matrix(C, n,n)
isSymetric(solve(diag(M))%*%matrix(C, n,n))
isSymmetric(solve(diag(M))%*%matrix(C, n,n))
dim(C)
C
length(C)
sqrt(840)
840/225
C
adj
length(adj)
lapply(1:n, function(i) which(sim_data$W[i, ] == 1))
num
adj
sim_data$W
dim(sim_data$W)
length(adj)
source("src/new_model.r")
source("src/new_model.r")
# run model without benchmarking
tic()
samples3 <- new_model(sim_data, bench = "none")
source("src/new_model.r")
# run model without benchmarking
tic()
samples3 <- new_model(sim_data, bench = "none")
# Prepare inputs for NIMBLE
n         <- length(sim_data$S)
neighbors <- lapply(1:n, function(i) which(sim_data$W[i, ] == 1))
num  <- sapply(neighbors, length)
adj <- unlist(neighbors)
mu <- rep(0, n)
eta <- 0.1
L <- length(adj)
M <- diag(1, n, n)
C <- sim_data$W
region_id <- sim_data$region_id
J         <- length(unique(region_id))
indicator <- matrix(0, J, n)
for (j in 1:J) indicator[j, ] <- as.numeric(region_id == j)
rho_max <- carMaxBound(C, adj, num, M)
solve(M)
solve(M)%*%W
W <- sim_data$W
solve(M)%*%W
c(sim_data$W)
adj
diag(M)%*%W
dim(diag(M)%*%W)
source("src/new_model.r")
# run model without benchmarking
tic()
samples3 <- new_model(sim_data, bench = "none")
toc()
# Diagnostics
traceplot(as.mcmc.list(samples3)[, c("rho", "log_kappa",
"S[1]", "S[5]", "S[50]",
"P[1]", "P[5]", "P[50]")])
gelman.diag(as.mcmc.list(samples3)[, c("rho", "log_kappa",
"S[1]", "S[5]", "S[50]",
"P[1]", "P[5]", "P[50]")],
autoburnin = FALSE)
effectiveSize(as.mcmc.list(samples3)[, c("rho", "log_kappa",
"S[1]", "S[5]", "S[50]",
"P[1]", "P[5]", "P[50]")])
as.mcmc.list(samples3)[, c("rho")]
mean(as.mcmc.list(samples3)[, c("rho")])
apply(as.mcmc.list(samples3)[, c("rho")], 1, mean)
apply(as.mcmc.list(samples3)[, c("rho")], 2, mean)
as.mcmc.list(samples3)[, c("rho")]
modeled_rho <- cbind(samples3$chain1[,"rho"])
mean(modeled_rho)
# Prepare inputs for NIMBLE
n         <- length(sim_data$S)
neighbors <- lapply(1:n, function(i) which(sim_data$W[i, ] == 1))
num  <- sapply(neighbors, length)
adj <- unlist(neighbors)
mu <- rep(0, n)
eta <- 0.1
L <- length(adj)
M <- rep(1, n)
C <- rep(1, length(adj))
region_id <- sim_data$region_id
J         <- length(unique(region_id))
indicator <- matrix(0, J, n)
for (j in 1:J) indicator[j, ] <- as.numeric(region_id == j)
rho_max <- carMaxBound(C, adj, num, M)
rho_max
source("src/new_model.r")
# run model without benchmarking
tic()
samples3 <- new_model(sim_data, bench = "none")
toc()
# Diagnostics
traceplot(as.mcmc.list(samples3)[, c("rho", "log_kappa",
"S[1]", "S[5]", "S[50]",
"P[1]", "P[5]", "P[50]")])
gelman.diag(as.mcmc.list(samples3)[, c("rho", "log_kappa",
"S[1]", "S[5]", "S[50]",
"P[1]", "P[5]", "P[50]")],
autoburnin = FALSE)
effectiveSize(as.mcmc.list(samples3)[, c("rho", "log_kappa",
"S[1]", "S[5]", "S[50]",
"P[1]", "P[5]", "P[50]")])
source("src/new_model.r")
# run model without benchmarking
tic()
samples3 <- new_model(sim_data, bench = "none")
num  <- sapply(neighbors, length)
adj <- unlist(neighbors)
weights <- rep(1, length(adj))
CM <- as.carCM(adj, weights, num)
C <- CM$C
M <- CM$M
dim(C)
dim(M)
CM
C <- CM$C
M <- CM$M
CM <- as.carCM(adj, weights, num)
C <- CM$C
M <- CM$M
length(C)
length(M)
source("src/new_model.r")
# run model without benchmarking
tic()
samples3 <- new_model(sim_data, bench = "none")
toc()
# Diagnostics
traceplot(as.mcmc.list(samples3)[, c("rho", "log_kappa",
"S[1]", "S[5]", "S[50]",
"P[1]", "P[5]", "P[50]")])
gelman.diag(as.mcmc.list(samples3)[, c("rho", "log_kappa",
"S[1]", "S[5]", "S[50]",
"P[1]", "P[5]", "P[50]")],
autoburnin = FALSE)
effectiveSize(as.mcmc.list(samples3)[, c("rho", "log_kappa",
"S[1]", "S[5]", "S[50]",
"P[1]", "P[5]", "P[50]")])
source("src/generate_data.r")
n <- 100 # number of points
rho <- 0.7 # spatial correlation
kappa <- 1.5 # precision scaling variable (for CAR)
tau <- 0.25 # related to census privacy budget
J <- 6  # number of regions
sim_data <- generate_data(n=n,
rho=rho,
kappa=kappa,
tau=tau,
J=J)
source("src/new_model.r")
# run model without benchmarking
tic()
samples3 <- new_model(sim_data, bench = "none")
toc()
# Diagnostics
traceplot(as.mcmc.list(samples3)[, c("rho", "log_kappa",
"S[1]", "S[5]", "S[50]",
"P[1]", "P[5]", "P[50]")])
gelman.diag(as.mcmc.list(samples3)[, c("rho", "log_kappa",
"S[1]", "S[5]", "S[50]",
"P[1]", "P[5]", "P[50]")],
autoburnin = FALSE)
effectiveSize(as.mcmc.list(samples3)[, c("rho", "log_kappa",
"S[1]", "S[5]", "S[50]",
"P[1]", "P[5]", "P[50]")])
true_Ps <- sim_data$P
obs_Ps <- sim_data$P_star
modeled_Ps_no_bench <- cbind(samples3$chain1[,paste0("P[", 1:100, "]")])
CIs_no_bench <- apply(X=modeled_Ps_no_bench, MARGIN=2 ,
FUN= function(x) quantile(x, probs = c(0.025, 0.975)))
print("No benchmarking coverage")
sum(ifelse(true_Ps >= CIs_no_bench[1,] & true_Ps <= CIs_no_bench[2,], 1, 0))/100
source("src/new_generate_data.r")
root_n <- 15 # root of number of points (to make grid with n observations)
rho <- 0.7 # spatial correlation
kappa <- 1.5 # precision scaling variable (for CAR)
tau <- 50 # related to census privacy budget
J <- 6  # number of regions
sim_data_new <- new_generate_data(root_n=root_n,
rho=rho,
kappa=kappa,
tau=tau,
J=J)
plot_neigh(sim_data_new, "regions")
plot_neigh(sim_data_new, "S")
plot_neigh(sim_data_new, "P")
source("src/new_model.r")
# run model without benchmarking
tic()
samples4 <- new_model(sim_data_new)
toc()
# Diagnostics
traceplot(as.mcmc.list(samples4)[, c("rho", "log_kappa",
"S[1]", "S[5]", "S[50]",
"P[1]", "P[5]", "P[50]")])
gelman.diag(as.mcmc.list(samples4)[, c("rho", "log_kappa",
"S[1]", "S[5]", "S[50]",
"P[1]", "P[5]", "P[50]")],
autoburnin = FALSE)
effectiveSize(as.mcmc.list(samples4)[, c("rho", "log_kappa",
"S[1]", "S[5]", "S[50]",
"P[1]", "P[5]", "P[50]")])
# Assuming you have your samples and sim_data objects:
plot_neigh(sim_data_new, "P")
modeled_Ps <- cbind(samples4$chain1[,paste0("P[", 1:100, "]")])
P_means <- apply(modeled_Ps, 2, mean)
plot_neigh(sim_data_new, "P", P_means)
length(NA)
# Assuming you have your samples and sim_data objects:
plot_neigh(sim_data_new, "P")
modeled_Ps <- cbind(samples4$chain1[,paste0("P[", 1:100, "]")])
P_means <- apply(modeled_Ps, 2, mean)
plot_neigh(sim_data_new, "P", P_means)
# sim_data$W       : n×n adjacency matrix
# sim_data$S       : latent log-intensities
# sim_data$P       : true counts
# sim_data$region_id: region labels
plot_neigh <- function(data, feature, post_means = NA){
# Set up a larger plotting area
par(mar = c(1,1,2,1))  # Reduce margins
# Build igraph object
g <- graph_from_adjacency_matrix(data$W, mode = "undirected")
# Layout (e.g. Fruchterman–Reingold)
# Layout with modified Fruchterman-Reingold parameters
layout_ij <- layout_with_fr(g,
niter = 1000
)
if (feature == "regions"){
# 1. Choose a palette with J distinct colors
J <- length(unique(data$region_id))
palette <- brewer.pal(min(J, 12), "Set3")
# 2. Assign each region its color
region_cols <- palette[data$region_id]
# 3. Plot, coloring nodes by region with larger sizes
plot(g,
layout        = layout_ij,
vertex.size   = 6,
vertex.color  = region_cols,
vertex.label  = NA,
edge.color    = "grey80",
edge.width    = 1)
# 4. Add a legend with larger text
legend("topright",
legend = paste("Region", sort(unique(data$region_id))),
col    = palette[sort(unique(data$region_id))],
pch    = 19,
bty    = "n")
}
if (feature == "S"){
# Color nodes by latent log‐intensity S
S_vals <- data$S
pal_S <- colorRampPalette(c("blue","white","red"))(100)
S_cols <- pal_S[ cut(S_vals, breaks=100, include.lowest=TRUE) ]
plot(g,
layout       = layout_ij,
vertex.size  = 6,
vertex.color = S_cols,
vertex.label = NA,
edge.color   = "grey80",
edge.width   = 1,
main         = "Adjacency graph colored by S")
}
if (feature == "P"){
# Get the range of values for the colorbar
P_vals <- data$P
if (length(post_means) > 1){
P_vals <- post_means
}
P_range <- range(P_vals)
pal_P <- colorRampPalette(c("lightyellow","darkorange","darkred"))(100)
P_cols <- pal_P[cut(P_vals, breaks=100, include.lowest=TRUE)]
# Set up layout to accommodate plot and legend
layout(matrix(c(1,2), ncol=2), widths=c(4,1))
# First plot: network
par(mar=c(1,1,2,1))
plot(g,
layout       = layout_ij,
vertex.size  = 6,
vertex.color = P_cols,
vertex.label = NA,
edge.color   = "grey80",
edge.width   = 1,
main         = "Adjacency graph colored by Population counts")
# Second plot: color legend
par(mar=c(1,2,2,4))
plot(c(0,2), P_range, type='n', axes=FALSE, xlab='', ylab='')
title('Count')
gradient <- as.raster(matrix(rev(pal_P), ncol=1))
rasterImage(gradient, 0, P_range[1], 1, P_range[2])
axis(4, at=seq(P_range[1], P_range[2], length.out=5),
las=1, cex.axis=0.8)
# Reset layout
layout(1)
}
}
plot_neigh(sim_data, "regions")
plot_neigh(sim_data, "S")
# Assuming you have your samples and sim_data objects:
plot_neigh(sim_data_new, "P")
modeled_Ps <- cbind(samples4$chain1[,paste0("P[", 1:100, "]")])
P_means <- apply(modeled_Ps, 2, mean)
plot_neigh(sim_data_new, "P", P_means)
# posterior median = observed? (if yes rmse's equal)
rmserr(true_Ps, obs_Ps)$rmse
rmserr(true_Ps, apply(X=modeled_Ps, MARGIN=2 , FUN=median))$rmse
# 95% CI coverage
CIs <- apply(X=modeled_Ps, MARGIN=2 ,
FUN= function(x) quantile(x, probs = c(0.025, 0.975)))
print("Coverage")
sum(ifelse(true_Ps >= CIs[1,] & true_Ps <= CIs[2,], 1, 0))/100
# run model with (exact) benchmarking
tic()
samples2.1 <- new_model(sim_data, bench = "inexact")
toc()
# Diagnostics
traceplot(as.mcmc.list(samples2.1)[, c("rho", "log_kappa",
"S[1]", "S[5]", "S[50]",
"P[1]", "P[5]", "P[50]")])
gelman.diag(as.mcmc.list(samples2.1)[, c("rho", "log_kappa",
"S[1]", "S[5]", "S[50]",
"P[1]", "P[5]", "P[50]")],
autoburnin = FALSE)
effectiveSize(as.mcmc.list(samples2.1)[, c("rho", "log_kappa",
"S[1]", "S[5]", "S[50]",
"P[1]", "P[5]", "P[50]")])
# Assuming you have your samples and sim_data objects:
plot_neigh(sim_data_new, "P")
modeled_Ps <- cbind(samples4$chain1[,paste0("P[", 1:100, "]")])
P_means <- apply(modeled_Ps, 2, mean)
plot_neigh(sim_data_new, "P", P_means)
# posterior median = observed? (if yes rmse's equal)
true_Ps <- sim_data_new$P
obs_Ps <- sim_data_new$P_star
rmserr(true_Ps, obs_Ps)$rmse
rmserr(true_Ps, apply(X=modeled_Ps, MARGIN=2 , FUN=median))$rmse
# Assuming you have your samples and sim_data objects:
plot_neigh(sim_data_new, "P")
modeled_Ps <- cbind(samples4$chain1[,paste0("P[", 1:root_n^2, "]")])
P_means <- apply(modeled_Ps, 2, mean)
plot_neigh(sim_data_new, "P", P_means)
# posterior median = observed? (if yes rmse's equal)
true_Ps <- sim_data_new$P
obs_Ps <- sim_data_new$P_star
rmserr(true_Ps, obs_Ps)$rmse
rmserr(true_Ps, apply(X=modeled_Ps, MARGIN=2 , FUN=median))$rmse
# 95% CI coverage
CIs <- apply(X=modeled_Ps, MARGIN=2 ,
FUN= function(x) quantile(x, probs = c(0.025, 0.975)))
print("Coverage")
sum(ifelse(true_Ps >= CIs[1,] & true_Ps <= CIs[2,], 1, 0))/100
# Assuming you have your samples and sim_data objects:
plot_neigh(sim_data_new, "P")
modeled_Ps <- cbind(samples4$chain1[,paste0("P[", 1:root_n^2, "]")])
P_means <- apply(modeled_Ps, 2, mean)
plot_neigh(sim_data_new, "P", P_means)
# posterior median = observed? (if yes rmse's equal)
true_Ps <- sim_data_new$P
obs_Ps <- sim_data_new$P_star
rmserr(true_Ps, obs_Ps)$rmse
rmserr(true_Ps, apply(X=modeled_Ps, MARGIN=2 , FUN=median))$rmse
# 95% CI coverage
CIs <- apply(X=modeled_Ps, MARGIN=2 ,
FUN= function(x) quantile(x, probs = c(0.025, 0.975)))
print("Coverage")
sum(ifelse(true_Ps >= CIs[1,] & true_Ps <= CIs[2,], 1, 0))/(root_n^2)
true_Ps <- sim_data$P
obs_Ps <- sim_data$P_star
modeled_Ps_bench <- cbind(samples2.1$chain1[,paste0("P[", 1:100, "]")])
modeled_Ps_no_bench <- cbind(samples3$chain1[,paste0("P[", 1:100, "]")])
# posterior median = observed? (if yes rmse's equal)
rmserr(true_Ps, obs_Ps)$rmse
rmserr(true_Ps, apply(X=modeled_Ps_bench, MARGIN=2 , FUN=median))$rmse
rmserr(true_Ps, apply(X=modeled_Ps_no_bench, MARGIN=2 , FUN=median))$rmse
# 95% CI coverage
CIs_bench <- apply(X=modeled_Ps_bench, MARGIN=2 ,
FUN= function(x) quantile(x, probs = c(0.025, 0.975)))
print("With benchmarking coverage")
sum(ifelse(true_Ps >= CIs_bench[1,] & true_Ps <= CIs_bench[2,], 1, 0))/100
CIs_no_bench <- apply(X=modeled_Ps_no_bench, MARGIN=2 ,
FUN= function(x) quantile(x, probs = c(0.025, 0.975)))
print("No benchmarking coverage")
sum(ifelse(true_Ps >= CIs_no_bench[1,] & true_Ps <= CIs_no_bench[2,], 1, 0))/100
?grph_from_adjacency_matrix
?graph_from_adjacency_matrix
modeled_Ps
source("src/new_model.r")
# run model with benchmarking
tic()
samples5 <- new_model(sim_data_new, bench = "inexact")
toc()
# Diagnostics
traceplot(as.mcmc.list(samples5)[, c("rho", "log_kappa",
"S[1]", "S[5]", "S[50]",
"P[1]", "P[5]", "P[50]")])
gelman.diag(as.mcmc.list(samples5)[, c("rho", "log_kappa",
"S[1]", "S[5]", "S[50]",
"P[1]", "P[5]", "P[50]")],
autoburnin = FALSE)
effectiveSize(as.mcmc.list(samples5)[, c("rho", "log_kappa",
"S[1]", "S[5]", "S[50]",
"P[1]", "P[5]", "P[50]")])
# Assuming you have your samples and sim_data objects:
plot_neigh(sim_data_new, "P")
modeled_Ps_no_bench2 <- cbind(samples4$chain1[,paste0("P[", 1:root_n^2, "]")])
P_means_no_bench <- apply(modeled_Ps_no_bench2, 2, mean)
plot_neigh(sim_data_new, "P", P_means_no_bench)
modeled_Ps_bench2 <- cbind(samples5$chain1[,paste0("P[", 1:root_n^2, "]")])
P_means_bench <- apply(modeled_Ps_bench2, 2, mean)
plot_neigh(sim_data_new, "P", P_means_bench)
# posterior median = observed? (if yes rmse's equal)
true_Ps <- sim_data_new$P
obs_Ps <- sim_data_new$P_star
rmserr(true_Ps, obs_Ps)$rmse
rmserr(true_Ps, apply(X=modeled_Ps_no_bench2, MARGIN=2 , FUN=median))$rmse
rmserr(true_Ps, apply(X=modeled_Ps_bench2, MARGIN=2 , FUN=median))$rmse
# 95% CI coverage
no_bench_CIs <- apply(X=modeled_Ps_no_bench2, MARGIN=2 ,
FUN= function(x) quantile(x, probs = c(0.025, 0.975)))
print("No benchmarking Coverage")
sum(ifelse(true_Ps >= CIs[1,] & true_Ps <= CIs[2,], 1, 0))/(root_n^2)
bench_CIs <- apply(X=modeled_Ps_no_bench2, MARGIN=2 ,
FUN= function(x) quantile(x, probs = c(0.025, 0.975)))
print("Inexact benchmarking Coverage")
sum(ifelse(true_Ps >= CIs[1,] & true_Ps <= CIs[2,], 1, 0))/(root_n^2)
# Assuming you have your samples and sim_data objects:
plot_neigh(sim_data_new, "P")
modeled_Ps_no_bench2 <- cbind(samples4$chain1[,paste0("P[", 1:root_n^2, "]")])
P_means_no_bench <- apply(modeled_Ps_no_bench2, 2, mean)
plot_neigh(sim_data_new, "P", P_means_no_bench)
modeled_Ps_bench2 <- cbind(samples5$chain1[,paste0("P[", 1:root_n^2, "]")])
P_means_bench <- apply(modeled_Ps_bench2, 2, mean)
plot_neigh(sim_data_new, "P", P_means_bench)
# posterior median = observed? (if yes rmse's equal)
true_Ps <- sim_data_new$P
obs_Ps <- sim_data_new$P_star
rmserr(true_Ps, obs_Ps)$rmse
rmserr(true_Ps, apply(X=modeled_Ps_no_bench2, MARGIN=2 , FUN=median))$rmse
rmserr(true_Ps, apply(X=modeled_Ps_bench2, MARGIN=2 , FUN=median))$rmse
# 95% CI coverage
no_bench_CIs <- apply(X=modeled_Ps_no_bench2, MARGIN=2 ,
FUN= function(x) quantile(x, probs = c(0.025, 0.975)))
print("No benchmarking Coverage")
sum(ifelse(true_Ps >= CIs[1,] & true_Ps <= CIs[2,], 1, 0))/(root_n^2)
bench_CIs <- apply(X=modeled_Ps_bench2, MARGIN=2 ,
FUN= function(x) quantile(x, probs = c(0.025, 0.975)))
print("Inexact benchmarking Coverage")
sum(ifelse(true_Ps >= CIs[1,] & true_Ps <= CIs[2,], 1, 0))/(root_n^2)
# Assuming you have your samples and sim_data objects:
plot_neigh(sim_data_new, "P")
modeled_Ps_no_bench2 <- cbind(samples4$chain1[,paste0("P[", 1:root_n^2, "]")])
P_means_no_bench <- apply(modeled_Ps_no_bench2, 2, mean)
plot_neigh(sim_data_new, "P", P_means_no_bench)
modeled_Ps_bench2 <- cbind(samples5$chain1[,paste0("P[", 1:root_n^2, "]")])
P_means_bench <- apply(modeled_Ps_bench2, 2, mean)
plot_neigh(sim_data_new, "P", P_means_bench)
# posterior median = observed? (if yes rmse's equal)
true_Ps <- sim_data_new$P
obs_Ps <- sim_data_new$P_star
rmserr(true_Ps, obs_Ps)$rmse
rmserr(true_Ps, apply(X=modeled_Ps_no_bench2, MARGIN=2 , FUN=median))$rmse
rmserr(true_Ps, apply(X=modeled_Ps_bench2, MARGIN=2 , FUN=median))$rmse
# 95% CI coverage
no_bench_CIs <- apply(X=modeled_Ps_no_bench2, MARGIN=2 ,
FUN= function(x) quantile(x, probs = c(0.025, 0.975)))
print("No benchmarking Coverage")
sum(ifelse(true_Ps >= no_bench_CIs[1,] & true_Ps <= no_bench_CIs[2,], 1, 0))/(root_n^2)
bench_CIs <- apply(X=modeled_Ps_bench2, MARGIN=2 ,
FUN= function(x) quantile(x, probs = c(0.025, 0.975)))
print("Inexact benchmarking Coverage")
sum(ifelse(true_Ps >= bench_CIs[1,] & true_Ps <= bench_CIs[2,], 1, 0))/(root_n^2)
bench_CIs
print("Inexact benchmarking Coverage")
sum(ifelse(true_Ps >= bench_CIs[1,] & true_Ps <= bench_CIs[2,], 1, 0))/(root_n^2)
# Assuming you have your samples and sim_data objects:
plot_neigh(sim_data_new, "P")
modeled_Ps_no_bench2 <- cbind(samples4$chain1[,paste0("P[", 1:root_n^2, "]")])
P_means_no_bench <- apply(modeled_Ps_no_bench2, 2, mean)
plot_neigh(sim_data_new, "P", P_means_no_bench)
modeled_Ps_bench2 <- cbind(samples5$chain1[,paste0("P[", 1:root_n^2, "]")])
P_means_bench <- apply(modeled_Ps_bench2, 2, mean)
plot_neigh(sim_data_new, "P", P_means_bench)
# posterior median = observed? (if yes rmse's equal)
true_Ps <- sim_data_new$P
obs_Ps <- sim_data_new$P_star
rmserr(true_Ps, obs_Ps)$rmse
rmserr(true_Ps, apply(X=modeled_Ps_no_bench2, MARGIN=2 , FUN=median))$rmse
rmserr(true_Ps, apply(X=modeled_Ps_bench2, MARGIN=2 , FUN=median))$rmse
# 95% CI coverage
no_bench_CIs <- apply(X=modeled_Ps_no_bench2, MARGIN=2 ,
FUN= function(x) quantile(x, probs = c(0.025, 0.975)))
print("No benchmarking Coverage")
sum(ifelse(true_Ps >= no_bench_CIs[1,] & true_Ps <= no_bench_CIs[2,], 1, 0))/(root_n^2)
bench_CIs <- apply(X=modeled_Ps_bench2, MARGIN=2 ,
FUN= function(x) quantile(x, probs = c(0.025, 0.975)))
print("Inexact benchmarking Coverage")
sum(ifelse(true_Ps >= bench_CIs[1,] & true_Ps <= bench_CIs[2,], 1, 0))/(root_n^2)
