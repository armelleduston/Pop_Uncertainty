---
title: "Population Uncertainty Project"
author: "Armelle Duston"
date: "`r Sys.Date()`"
output: pdf_document
---

## Setup and Libraries

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

knitr::opts_chunk$set(warning = F, message = F, echo = F)

### Load Packages 
library(ggplot2)
library(tidyr)
library(patchwork)
library(dplyr)
library(knitr)
library(kableExtra)
library(MASS)
library(nimble)
library(coda)
library(extraDistr)
library(igraph)
library(RColorBrewer)
library(nimbleNoBounds)
library(pracma)
library(gridExtra)

### ggplot theme
theme_set(theme_bw() +
            theme(plot.title = element_text(hjust = 0.5, size = 16),
                  plot.subtitle = element_text(hjust = 0.5, size = 12),
                  axis.title = element_text(size = 12),
                  axis.text = element_text(size = 10),
                  strip.text = element_text(size = 12),
                  legend.position = "bottom"))

# if (rstudioapi::isAvailable()) {
#   setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
# }
```


## Generate Data

```{r generate_data}

source("src/generate_data.r")

n <- 100 # number of points
rho <- 0.7 # spatial correlation       
kappa <- 1.5 # precision scaling variable (for CAR)
tau <- 0.25 # related to census privacy budget     
J <- 6  # number of regions


sim_data <- generate_data(n=n, 
                          rho=rho, 
                          kappa=kappa, 
                          tau=tau,
                          J=J)


```

### Plot neighborhood structure

```{r plot_neighborhood}

# sim_data$W       : n×n adjacency matrix
# sim_data$S       : latent log-intensities
# sim_data$P       : true counts
# sim_data$region_id: region labels  

plot_neigh <- function(data, feature, post_means = NA){
  # Set up a larger plotting area
  par(mar = c(1,1,2,1))  # Reduce margins
  
  # Build igraph object
  g <- graph_from_adjacency_matrix(data$W, 
                                   mode = "undirected")
  # Layout (e.g. Fruchterman–Reingold)
  # Layout with modified Fruchterman-Reingold parameters
  layout_ij <- layout_with_fr(g,
                               niter = 1000
    )
  
  if (feature == "regions"){
    # 1. Choose a palette with J distinct colors
    J <- length(unique(data$region_id))
    palette <- brewer.pal(min(J, 12), "Set3")  
    
    # 2. Assign each region its color
    region_cols <- palette[data$region_id]
    
    # 3. Plot, coloring nodes by region with larger sizes
    plot(g, 
         layout        = layout_ij,
         vertex.size   = 6,         
         vertex.color  = region_cols,
         vertex.label  = NA,
         edge.color    = "grey80",
         edge.width    = 1)          

    # 4. Add a legend with larger text
    legend("topright",
           legend = paste("Region", sort(unique(data$region_id))),
           col    = palette[sort(unique(data$region_id))],
           pch    = 19,
           bty    = "n")
  }
  
  if (feature == "S"){
    # Color nodes by latent log‐intensity S
    S_vals <- data$S
    pal_S <- colorRampPalette(c("blue","white","red"))(100)
    S_cols <- pal_S[ cut(S_vals, breaks=100, include.lowest=TRUE) ]
    
    plot(g,
         layout       = layout_ij,
         vertex.size  = 6,          
         vertex.color = S_cols,
         vertex.label = NA,
         edge.color   = "grey80",
         edge.width   = 1,          
         main         = "Adjacency graph colored by S")         
  }
  
  if (feature == "P"){
    # Get the range of values for the colorbar
    P_vals <- data$P
    if (length(post_means) > 1){
      P_vals <- post_means
    }
    P_range <- range(P_vals)
    pal_P <- colorRampPalette(c("lightyellow","darkorange","darkred"))(100)
    P_cols <- pal_P[cut(P_vals, breaks=100, include.lowest=TRUE)]
    
    # Set up layout to accommodate plot and legend
    layout(matrix(c(1,2), ncol=2), widths=c(4,1))
    
    # First plot: network
    par(mar=c(1,1,2,1))
    plot(g,
         layout       = layout_ij,
         vertex.size  = 6,          
         vertex.color = P_cols,
         vertex.label = NA,
         edge.color   = "grey80",
         edge.width   = 1,           
         main         = "Adjacency graph colored by Population counts")
    
    # Second plot: color legend
    par(mar=c(1,2,2,4))
    plot(c(0,2), P_range, type='n', axes=FALSE, xlab='', ylab='')
    title('Count')
    gradient <- as.raster(matrix(rev(pal_P), ncol=1))
    rasterImage(gradient, 0, P_range[1], 1, P_range[2])
    axis(4, at=seq(P_range[1], P_range[2], length.out=5), 
         las=1, cex.axis=0.8)
    
    # Reset layout
    layout(1)
  }
}


plot_neigh(sim_data, "regions")
plot_neigh(sim_data, "S")

```


### Spatial-only Bayesian Model

Get just the spatial piece working

```{r spatial_only}

# source("src/spatial_only.r")
# 
# samples1 <- spatial_only(sim_data)
# 
# # Diagnostics
# traceplot(as.mcmc.list(samples1)[, c("rho", "log_kappa", "S[1]", "S[25]", "S[50]")])
# 
# gelman.diag(as.mcmc.list(samples1)[, c("rho", "log_kappa", "S[1]", "S[25]", "S[50]")], 
#             autoburnin = FALSE)
# effectiveSize(as.mcmc.list(samples1)[, c("rho", "log_kappa", "S[1]", "S[25]", "S[50]")])
#   
  
```


## Spatial + DP noise + benchmarking Bayesian Model

### Write discrete laplace function
Rather than injecting laplace noise and rounding, simply use discrete laplace (is this reasonable?)

```{r ddlaplace_nimble_function}

# # Define the ddlaplace_nim distribution for NIMBLE
# ddlaplace_nim <- nimbleFunction(
#   run = function(x = double(0), 
#                  mu = double(0), 
#                  tau = double(0), 
#                  log = integer(0, default = 0)) {
#     returnType(double(0))
#     
#     # Parameter checks
#     if(tau <= 0) return(NaN)
#     
#     # Calculate lambda parameter (lambda = exp(-1/tau))
#     lambda <- exp(-1/tau)
#     
#     # Calculate normalization constant
#     c <- (1 - lambda) / (1 + lambda)
#     
#     # Calculate PMF
#     logProb <- log(c) + abs(x - mu) * log(lambda)
#     
#     # Return log or natural probability
#     if(log) return(logProb)
#     else return(exp(logProb))
#   }
# )
# 
# # Define the simulation function without using rgeom
# rdlaplace_nim <- nimbleFunction(
#   run = function(n = integer(0), mu = double(0), tau = double(0)) {
#     returnType(double(0))
#     
#     # Parameter check
#     if(tau <= 0) return(NaN)
#     if(n != 1) stop("rdlaplace_nim only handles n = 1")
#     
#     # Calculate lambda
#     lambda <- exp(-1/tau)
#     
#     # Probability of X <= mu
#     p_leq_mu <- 1 / (1 + lambda)
#     
#     # Decide direction using uniform random number
#     u <- runif(1)
#     if(u < p_leq_mu) {
#       # X <= mu (including equality)
#       # Instead of using rgeom, implement geometric sampling directly
#       v <- runif(1)
#       # Convert uniform to geometric: k = floor(log(v) / log(lambda))
#       k <- floor(log(v) / log(1 - lambda))
#       return(mu - k)
#     } else {
#       # X > mu
#       v <- runif(1)
#       # Convert uniform to geometric: k = floor(log(v) / log(lambda))
#       k <- floor(log(v) / log(1 - lambda))
#       return(mu + k + 1)
#     }
#   }
# )
# 
# # Register the distribution with NIMBLE
# registerDistributions(list(
#   ddlaplace_nim = list(
#     BUGSdist = "ddlaplace_nim(mu, tau)",
#     discrete = TRUE,
#     types = c('value = double(0)', 'mu = double(0)', 'tau = double(0)'),
#     pqAvail = FALSE,
#     range = c(-Inf, Inf)
#   )
# ))


```


### Write rounded Normal nimble dist

```{r droundnorm_nimble_function}

droundnorm <- nimbleFunction(
  run = function(x = double(0),    
                 mu = double(0),   
                 sigma = double(0),   
                 log = double(0, default = 0)) {
    returnType(double(0))
    # Support: x must be (near) integer
    if (abs(x - round(x)) > 1e-8) {
      if (log == 1) return(-Inf)
      return(0.0)
    }
    if (sigma <= 0) {
      if (log == 1) return(-Inf)
      return(0.0)
    }
    a <- (x - 0.5 - mu) / sigma
    b <- (x + 0.5 - mu) / sigma
    p <- pnorm(b, 0, 1) - pnorm(a, 0, 1)   # CDF difference
    # Guard tiny probabilities to avoid log(0)
    if (p <= 0) {
      if (log == 1) return(-Inf)
      return(0.0)
    }
    if (log == 1) return(log(p))
    return(p)
  }
)

# RNG: sample normal then round to nearest integer
rroundnorm <- nimbleFunction(
  run = function(n = integer(0), mu = double(0), sigma = double(0)) {
    returnType(integer(0))
    if (n != 1) nimPrint("rroundnorm generates one value; ignoring n")
    if (sigma <= 0) nimStop("sigma must be > 0")
    z <- rnorm(1, mean = mu, sd = sigma)
    return(round(z))
  }
)

# Register for BUGS usage
registerDistributions(list(
  droundnorm = list(
    BUGSdist = "droundnorm(mu, sigma)",
    types    = c("value = double(0)", "mu = double(0)", "sigma = double(0)"),
    discrete = TRUE
  )
))



```


### Complete model with exact benchmarking

(currently doesn't converge, maybe add a smarter sampler)

```{r with_exact_bench}
source("src/new_model.r")

# run model with (exact) benchmarking

tic()
samples2 <- new_model(sim_data, bench = "exact")
toc()

# Diagnostics
traceplot(as.mcmc.list(samples2)[, c("rho", "log_kappa", 
                                     "S[1]", "S[5]", "S[50]", 
                                     "P[1]", "P[5]", "P[50]")])

gelman.diag(as.mcmc.list(samples2)[, c("rho", "log_kappa", 
                                     "S[1]", "S[5]", "S[50]", 
                                     "P[1]", "P[5]", "P[50]")], 
            autoburnin = FALSE)
effectiveSize(as.mcmc.list(samples2)[, c("rho", "log_kappa", 
                                     "S[1]", "S[5]", "S[50]", 
                                     "P[1]", "P[5]", "P[50]")])



```

### Complete model with inexact benchmarking


```{r with_inexact_bench}
# run model with (exact) benchmarking

tic()
samples2.1 <- new_model(sim_data, bench = "inexact")
toc()

# Diagnostics
traceplot(as.mcmc.list(samples2.1)[, c("rho", "log_kappa", 
                                     "S[1]", "S[5]", "S[50]", 
                                     "P[1]", "P[5]", "P[50]")])

gelman.diag(as.mcmc.list(samples2.1)[, c("rho", "log_kappa", 
                                     "S[1]", "S[5]", "S[50]", 
                                     "P[1]", "P[5]", "P[50]")], 
            autoburnin = FALSE)
effectiveSize(as.mcmc.list(samples2.1)[, c("rho", "log_kappa", 
                                     "S[1]", "S[5]", "S[50]", 
                                     "P[1]", "P[5]", "P[50]")])



```

### Complete model without benchmarking

```{r without_bench}

source("src/new_model.r")

# run model without benchmarking

tic()
samples3 <- new_model(sim_data, bench = "none")
toc()

# Diagnostics
traceplot(as.mcmc.list(samples3)[, c("rho", "log_kappa", 
                                     "S[1]", "S[5]", "S[50]", 
                                     "P[1]", "P[5]", "P[50]")])

gelman.diag(as.mcmc.list(samples3)[, c("rho", "log_kappa", 
                                     "S[1]", "S[5]", "S[50]", 
                                     "P[1]", "P[5]", "P[50]")], 
            autoburnin = FALSE)
effectiveSize(as.mcmc.list(samples3)[, c("rho", "log_kappa", 
                                     "S[1]", "S[5]", "S[50]", 
                                     "P[1]", "P[5]", "P[50]")])

```


### Model Evaluation 


Compare modeled vs true P's

```{r}

true_Ps <- sim_data$P
obs_Ps <- sim_data$P_star
modeled_Ps_bench <- cbind(samples2.1$chain1[,paste0("P[", 1:100, "]")])
modeled_Ps_no_bench <- cbind(samples3$chain1[,paste0("P[", 1:100, "]")])

# posterior median = observed? (if yes rmse's equal)
rmserr(true_Ps, obs_Ps)$rmse 
rmserr(true_Ps, apply(X=modeled_Ps_bench, MARGIN=2 , FUN=median))$rmse
rmserr(true_Ps, apply(X=modeled_Ps_no_bench, MARGIN=2 , FUN=median))$rmse

# 95% CI coverage
CIs_bench <- apply(X=modeled_Ps_bench, MARGIN=2 , 
      FUN= function(x) quantile(x, probs = c(0.025, 0.975))) 

print("With benchmarking coverage")
sum(ifelse(true_Ps >= CIs_bench[1,] & true_Ps <= CIs_bench[2,], 1, 0))/100

CIs_no_bench <- apply(X=modeled_Ps_no_bench, MARGIN=2 , 
      FUN= function(x) quantile(x, probs = c(0.025, 0.975))) 

print("No benchmarking coverage")
sum(ifelse(true_Ps >= CIs_no_bench[1,] & true_Ps <= CIs_no_bench[2,], 1, 0))/100


```

## Realistic Data Model 

### Generate Data

```{r fig.width=12, fig.height=6}

source("src/new_generate_data.r")

root_n <- 15 # root of number of points (to make grid with n observations)
rho <- 0.7 # spatial correlation       
kappa <- 1.5 # precision scaling variable (for CAR)
tau <- 50 # related to census privacy budget     
J <- 6  # number of regions


sim_data_new <- new_generate_data(root_n=root_n, 
                          rho=rho, 
                          kappa=kappa, 
                          tau=tau,
                          J=J)

plot_neigh(sim_data_new, "regions")
plot_neigh(sim_data_new, "S")
plot_neigh(sim_data_new, "P")

```

### Run model with realistic data (no benchmark)

```{r}
source("src/new_model.r")

# run model without benchmarking

tic()
samples4 <- new_model(sim_data_new)
toc()

# Diagnostics
traceplot(as.mcmc.list(samples4)[, c("rho", "log_kappa", 
                                     "S[1]", "S[5]", "S[50]", 
                                     "P[1]", "P[5]", "P[50]")])

gelman.diag(as.mcmc.list(samples4)[, c("rho", "log_kappa", 
                                     "S[1]", "S[5]", "S[50]", 
                                     "P[1]", "P[5]", "P[50]")], 
            autoburnin = FALSE)
effectiveSize(as.mcmc.list(samples4)[, c("rho", "log_kappa", 
                                     "S[1]", "S[5]", "S[50]", 
                                     "P[1]", "P[5]", "P[50]")])
```


### Run model with realistic data (no benchmark)

```{r}
source("src/new_model.r")

# run model with benchmarking

tic()
samples5 <- new_model(sim_data_new, bench = "inexact")
toc()

# Diagnostics
traceplot(as.mcmc.list(samples5)[, c("rho", "log_kappa", 
                                     "S[1]", "S[5]", "S[50]", 
                                     "P[1]", "P[5]", "P[50]")])

gelman.diag(as.mcmc.list(samples5)[, c("rho", "log_kappa", 
                                     "S[1]", "S[5]", "S[50]", 
                                     "P[1]", "P[5]", "P[50]")], 
            autoburnin = FALSE)
effectiveSize(as.mcmc.list(samples5)[, c("rho", "log_kappa", 
                                     "S[1]", "S[5]", "S[50]", 
                                     "P[1]", "P[5]", "P[50]")])
```



### Model Evaluation for realistic data

Compare modeled vs true P's

```{r fig.width=12, fig.height=6}

# Assuming you have your samples and sim_data objects:
plot_neigh(sim_data_new, "P")

modeled_Ps_no_bench2 <- cbind(samples4$chain1[,paste0("P[", 1:root_n^2, "]")])
P_means_no_bench <- apply(modeled_Ps_no_bench2, 2, mean)
plot_neigh(sim_data_new, "P", P_means_no_bench)

modeled_Ps_bench2 <- cbind(samples5$chain1[,paste0("P[", 1:root_n^2, "]")])
P_means_bench <- apply(modeled_Ps_bench2, 2, mean)
plot_neigh(sim_data_new, "P", P_means_bench)

# posterior median = observed? (if yes rmse's equal)
true_Ps <- sim_data_new$P
obs_Ps <- sim_data_new$P_star

rmserr(true_Ps, obs_Ps)$rmse 
rmserr(true_Ps, apply(X=modeled_Ps_no_bench2, MARGIN=2 , FUN=median))$rmse
rmserr(true_Ps, apply(X=modeled_Ps_bench2, MARGIN=2 , FUN=median))$rmse

# 95% CI coverage
no_bench_CIs <- apply(X=modeled_Ps_no_bench2, MARGIN=2 , 
      FUN= function(x) quantile(x, probs = c(0.025, 0.975))) 

print("No benchmarking Coverage")
sum(ifelse(true_Ps >= no_bench_CIs[1,] & true_Ps <= no_bench_CIs[2,], 1, 0))/(root_n^2)

bench_CIs <- apply(X=modeled_Ps_bench2, MARGIN=2 , 
      FUN= function(x) quantile(x, probs = c(0.025, 0.975))) 

print("Inexact benchmarking Coverage")
sum(ifelse(true_Ps >= bench_CIs[1,] & true_Ps <= bench_CIs[2,], 1, 0))/(root_n^2)


```
