---
title: "Population Uncertainty Project"
author: "Armelle Duston"
date: "`r Sys.Date()`"
output: pdf_document
---

## Setup and Libraries

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

knitr::opts_chunk$set(warning = F, message = F, echo = F)

### Load Packages 
library(ggplot2)
library(tidyr)
library(patchwork)
library(dplyr)
library(knitr)
library(kableExtra)
library(MASS)
library(nimble)
library(coda)
library(extraDistr)
library(igraph)
library(RColorBrewer)
library(nimbleNoBounds)
library(pracma)

### ggplot theme
theme_set(theme_bw() +
            theme(plot.title = element_text(hjust = 0.5, size = 16),
                  plot.subtitle = element_text(hjust = 0.5, size = 12),
                  axis.title = element_text(size = 12),
                  axis.text = element_text(size = 10),
                  strip.text = element_text(size = 12),
                  legend.position = "bottom"))

if (rstudioapi::isAvailable()) {
  setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
}
```


## Generate Data

```{r generate_data}

source("src/generate_data.r")

n <- 100 # number of points
rho <- 0.7 # spatial correlation       
kappa <- 1.5 # precision scaling variable (for CAR)
tau <- 0.25 # related to census privacy budget     
J <- 10  # number of regions


sim_data <- generate_data(n=n, 
                          rho=rho, 
                          kappa=kappa, 
                          tau=tau,
                          J=J)


```

### Plot neighborhood structure

```{r plot_neighborhood}

# sim_data$W       : n×n adjacency matrix
# sim_data$S       : latent log-intensities
# sim_data$P       : true counts
# sim_data$region_id: region labels  


# Build igraph object
g <- graph_from_adjacency_matrix(sim_data$W, mode = "undirected")

# Layout (e.g. Fruchterman–Reingold)
layout_ij <- layout_with_fr(g)

# 1. Choose a palette with J distinct colors
J <- length(unique(sim_data$region_id))
palette <- brewer.pal(min(J, 12), "Set3")  # up to 12 colors; you can pick another brewer palette

# 2. Assign each region its color
region_cols <- palette[sim_data$region_id]

# 3. Plot, coloring nodes by region
plot(g, 
     layout        = layout_ij,
     vertex.size   = 6,
     vertex.color  = region_cols,
     vertex.label  = NA,
     edge.color    = "grey80",
     main          = "Adjacency Graph with Regions")

# 4. Add a legend
legend("topright",
       legend = paste("Region", sort(unique(sim_data$region_id))),
       col    = palette[sort(unique(sim_data$region_id))],
       pch    = 19,
       pt.cex = 1.5,
       bty    = "n")


# Color nodes by latent log‐intensity S
S_vals <- sim_data$S
# build a 100‐step palette
pal_S <- colorRampPalette(c("blue","white","red"))(100)
# cut S into 100 bins
S_cols <- pal_S[ cut(S_vals, breaks=100, include.lowest=TRUE) ]

plot(g,
     layout       = layout_ij,
     vertex.size  = 6,
     vertex.color = S_cols,
     vertex.label = NA,
     edge.color   = "grey80",
     main         = "Adjacency graph colored by latent log-intensity")


```


### Spatial-only Bayesian Model

Get just the spatial piece working

```{r spatial_only}

# source("src/spatial_only.r")
# 
# samples1 <- spatial_only(sim_data)
# 
# # Diagnostics
# traceplot(as.mcmc.list(samples1)[, c("rho", "log_kappa", "S[1]", "S[25]", "S[50]")])
# 
# gelman.diag(as.mcmc.list(samples1)[, c("rho", "log_kappa", "S[1]", "S[25]", "S[50]")], 
#             autoburnin = FALSE)
# effectiveSize(as.mcmc.list(samples1)[, c("rho", "log_kappa", "S[1]", "S[25]", "S[50]")])
#   
  
```


## Spatial + DP noise + benchmarking Bayesian Model

### Write discrete laplace function
Rather than injecting laplace noise and rounding, simply use discrete laplace (is this reasonable?)

```{r ddlaplace_nimble_function}

# # Define the ddlaplace_nim distribution for NIMBLE
# ddlaplace_nim <- nimbleFunction(
#   run = function(x = double(0), 
#                  mu = double(0), 
#                  tau = double(0), 
#                  log = integer(0, default = 0)) {
#     returnType(double(0))
#     
#     # Parameter checks
#     if(tau <= 0) return(NaN)
#     
#     # Calculate lambda parameter (lambda = exp(-1/tau))
#     lambda <- exp(-1/tau)
#     
#     # Calculate normalization constant
#     c <- (1 - lambda) / (1 + lambda)
#     
#     # Calculate PMF
#     logProb <- log(c) + abs(x - mu) * log(lambda)
#     
#     # Return log or natural probability
#     if(log) return(logProb)
#     else return(exp(logProb))
#   }
# )
# 
# # Define the simulation function without using rgeom
# rdlaplace_nim <- nimbleFunction(
#   run = function(n = integer(0), mu = double(0), tau = double(0)) {
#     returnType(double(0))
#     
#     # Parameter check
#     if(tau <= 0) return(NaN)
#     if(n != 1) stop("rdlaplace_nim only handles n = 1")
#     
#     # Calculate lambda
#     lambda <- exp(-1/tau)
#     
#     # Probability of X <= mu
#     p_leq_mu <- 1 / (1 + lambda)
#     
#     # Decide direction using uniform random number
#     u <- runif(1)
#     if(u < p_leq_mu) {
#       # X <= mu (including equality)
#       # Instead of using rgeom, implement geometric sampling directly
#       v <- runif(1)
#       # Convert uniform to geometric: k = floor(log(v) / log(lambda))
#       k <- floor(log(v) / log(1 - lambda))
#       return(mu - k)
#     } else {
#       # X > mu
#       v <- runif(1)
#       # Convert uniform to geometric: k = floor(log(v) / log(lambda))
#       k <- floor(log(v) / log(1 - lambda))
#       return(mu + k + 1)
#     }
#   }
# )
# 
# # Register the distribution with NIMBLE
# registerDistributions(list(
#   ddlaplace_nim = list(
#     BUGSdist = "ddlaplace_nim(mu, tau)",
#     discrete = TRUE,
#     types = c('value = double(0)', 'mu = double(0)', 'tau = double(0)'),
#     pqAvail = FALSE,
#     range = c(-Inf, Inf)
#   )
# ))


```


### Write NIMBLE distribution for rounded Normal

```{r droundnorm_nimble_function}

droundnorm <- nimbleFunction(
  run = function(x = double(0), mu = double(0), sigma = double(0), log = integer(0)) {
    returnType(double(0))
    # Support: x must be (near) integer
    if (abs(x - round(x)) > 1e-8) {
      if (log == 1) return(-Inf)
      return(0.0)
    }
    if (sigma <= 0) {
      if (log == 1) return(-Inf)
      return(0.0)
    }
    a <- (x - 0.5 - mu) / sigma
    b <- (x + 0.5 - mu) / sigma
    p <- pnorm(b, 0, 1) - pnorm(a, 0, 1)   # CDF difference
    # Guard tiny probabilities to avoid log(0)
    if (p <= 0) {
      if (log == 1) return(-Inf)
      return(0.0)
    }
    if (log == 1) return(log(p))
    return(p)
  }
)

# RNG: sample normal then round to nearest integer
rroundnorm <- nimbleFunction(
  run = function(n = integer(0), mu = double(0), sigma = double(0)) {
    returnType(double(0))
    if (n != 1) nimPrint("rroundnorm generates one value; ignoring n")
    if (sigma <= 0) nimStop("sigma must be > 0")
    z <- rnorm(1, mean = mu, sd = sigma)
    return(round(z))
  }
)

# Register for BUGS usage
registerDistributions(list(
  droundnorm = list(
    BUGSdist = "droundnorm(mu, sigma)",
    types    = c("value = double(0)", "mu = double(0)", "sigma = double(0)"),
    discrete = TRUE
  )
))



```


### Complete model with exact benchmarking

(currently doesn't converge, maybe add a smarter sampler)

```{r with_bench}
source("src/new_model.r")

# run model with (exact) benchmarking

tic()
samples2 <- new_model(sim_data, bench = TRUE)
toc()

# Diagnostics
traceplot(as.mcmc.list(samples2)[, c("rho", "log_kappa", 
                                     "S[1]", "S[5]", "S[50]", 
                                     "P[1]", "P[5]", "P[50]")])

gelman.diag(as.mcmc.list(samples2)[, c("rho", "log_kappa", 
                                     "S[1]", "S[5]", "S[50]", 
                                     "P[1]", "P[5]", "P[50]")], 
            autoburnin = FALSE)
effectiveSize(as.mcmc.list(samples2)[, c("rho", "log_kappa", 
                                     "S[1]", "S[5]", "S[50]", 
                                     "P[1]", "P[5]", "P[50]")])



```

### Complete model with inexact benchmarking

```{r without_bench}

source("src/new_model.r")

# run model without benchmarking


tic()
samples3 <- new_model(sim_data, bench = FALSE)
toc()

# Diagnostics
traceplot(as.mcmc.list(samples3)[, c("rho", "log_kappa", 
                                     "S[1]", "S[5]", "S[50]", 
                                     "P[1]", "P[5]", "P[50]")])

gelman.diag(as.mcmc.list(samples3)[, c("rho", "log_kappa", 
                                     "S[1]", "S[5]", "S[50]", 
                                     "P[1]", "P[5]", "P[50]")], 
            autoburnin = FALSE)
effectiveSize(as.mcmc.list(samples3)[, c("rho", "log_kappa", 
                                     "S[1]", "S[5]", "S[50]", 
                                     "P[1]", "P[5]", "P[50]")])


```


### Model Evaluation 

Compare modeled vs true P's

```{r}

true_Ps <- sim_data$P
obs_Ps <- sim_data$P_star
modeled_Ps_bench <- cbind(samples2$chain1[,paste0("P[", 1:100, "]")])
modeled_Ps_no_bench <- cbind(samples3$chain1[,paste0("P[", 1:100, "]")])

# posterior median = observed? (if yes rmse's equal)
rmserr(true_Ps, obs_Ps)$rmse 
rmserr(true_Ps, apply(X=modeled_Ps_bench, MARGIN=2 , FUN=median))$rmse
rmserr(true_Ps, apply(X=modeled_Ps_no_bench, MARGIN=2 , FUN=median))$rmse

# 95% CI coverage
CIs_bench <- apply(X=modeled_Ps_bench, MARGIN=2 , 
      FUN= function(x) quantile(x, probs = c(0.025, 0.975))) 

print("No benchmarking coverage")
sum(ifelse(true_Ps >= CIs_bench[1,] & true_Ps <= CIs_bench[2,], 1, 0))/100

CIs_no_bench <- apply(X=modeled_Ps_no_bench, MARGIN=2 , 
      FUN= function(x) quantile(x, probs = c(0.025, 0.975))) 

print("No benchmarking (new model) coverage")
sum(ifelse(true_Ps >= CIs_no_bench[1,] & true_Ps <= CIs_no_bench[2,], 1, 0))/100


```

## Realistic Data Model 

### Generate Data

```{r}

source("src/new_generate_data.r")

n <- 100 # number of points
rho <- 0.7 # spatial correlation       
kappa <- 1.5 # precision scaling variable (for CAR)
tau <- 0.25 # related to census privacy budget     
J <- 10  # number of regions


sim_data_new <- new_generate_data(n=n, 
                          rho=rho, 
                          kappa=kappa, 
                          tau=tau,
                          J=J)
  
  
```

### Run model with realistic data (no benchmark)

```{r}

source("src/new_data_model.r")

# run model without benchmarking


tic()
samples4 <- new_data_model(sim_data_new, bench = FALSE)
toc()

# Diagnostics
traceplot(as.mcmc.list(samples4)[, c("rho", "log_kappa",
                                     "S[1]", "P[1]")])

gelman.diag(as.mcmc.list(samples4)[, c("rho", "log_kappa",
                                     "S[1]", "P[1]")], 
            autoburnin = FALSE)
effectiveSize(as.mcmc.list(samples4)[, c("rho", "log_kappa",
                                     "S[1]", "P[1]")])

```

### Model Evaluation for realistic data

Compare modeled vs true P's

```{r}


modeled_Ps <- cbind(samples4$chain1[,paste0("P[", 1:100, "]")])

# posterior median = observed? (if yes rmse's equal)
rmserr(true_Ps, obs_Ps)$rmse 
rmserr(true_Ps, apply(X=modeled_Ps, MARGIN=2 , FUN=median))$rmse

# 95% CI coverage
CIs <- apply(X=modeled_Ps, MARGIN=2 , 
      FUN= function(x) quantile(x, probs = c(0.025, 0.975))) 

print("Coverage")
sum(ifelse(true_Ps >= CIs[1,] & true_Ps <= CIs[2,], 1, 0))/100


```
